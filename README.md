# Deep-Learning-Lab
MTech Research Deep Learning Lab Experiments

## Experiment: 1
Create 1D, 2D, and 3D tensors using PyTorch and NumPy.
Show Basic Operations: Element-wise addition, subtraction, multiplication, and division.
Dot product and matrix multiplication.
Indexing and Slicing examples (Boolean masking, extracting subtensors)
Use .view(), .reshape(), .unsqueeze(), and .squeeze() in PyTorch. Compare with .reshape in Numpy
Broadcasting- Perform operations with tensors of different shapes.
In-place vs Out-of-place operations

## Experiment: 2 
Neural Network from Scratch using Numpy on MNIST dataset

## Experiment 3 : 
Implementation of a simple neural network to classify both linearly separable and non-linearly separable datasets, using Numpy.

The objective of this experiment is to design and implement a simple neural network from scratch using NumPy to classify two types of datasets:Linearly separable dataset (make_classification)
This experiment helps in understanding:
How a perceptron learns a linear decision boundary.
Why a single-layer neural network fails for non-linear problems.
How adding hidden layers and non-linear activation functions enables learning complex decision boundaries.
For a linearly separable dataset, a single-layer perceptron is sufficient.
For a non-linearly separable dataset, a multi-layer neural network with at least one hidden layer and non-linear activation (Sigmoid/Tanh/ReLU) is required.
